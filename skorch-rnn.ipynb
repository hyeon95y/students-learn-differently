{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dstoolbox.transformers import Padder2d\n",
    "from dstoolbox.transformers import TextFeaturizer\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "F = nn.functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000  # This is on the low end\n",
    "MAX_LEN = 50  # Texts are pretty long on average, this is on the low end\n",
    "USE_CUDA = True  # Set this to False if you don't want to use CUDA\n",
    "NUM_CV_STEPS = 10  # Number of randomized search steps to perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"aclImdb\"):\n",
    "    # unzip data if it does not exist\n",
    "    with tarfile.open(\"aclImdb_v1.tar.gz\", \"r:gz\") as f:\n",
    "        f.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files(\"aclImdb/train/\", categories=[\"pos\", \"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset[\"data\"], dataset[\"target\"]\n",
    "X = np.asarray([x.decode() for x in X])  # decode from bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: pos\n",
      "Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n",
      "\n",
      "Target: neg\n",
      "Words can't describe how bad this movie is. I can't explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clichés, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won't list them here, but just mention the coloring of the plane. They didn't even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you're choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.\n",
      "\n",
      "Target: pos\n",
      "Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it´d be an investment!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, target in zip(X[:3], y):\n",
    "    print(\"Target: {}\".format(dataset[\"target_names\"][target]))\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220,  48, 104, 217, 190, 186,  63, 156, 186, 207, 193,  29, 218,\n",
       "        117, 215,  57, 205, 184,  54,  43, 129, 173, 199, 169, 181,  39,\n",
       "        102,  35, 205, 128,  19,  26,  27, 120, 133,  23,  76, 193,  95,\n",
       "        206,  87,  49, 190, 210,  77,  44,  38,  98, 140, 190],\n",
       "       [213,  33,  52,  94,  18, 187, 124, 101,  33,  67, 102,  32, 216,\n",
       "        137, 217,  87, 191, 163, 102,  76, 219, 190,  78,  17,  83, 133,\n",
       "         94,  93, 124, 158,  33,  19, 132, 179, 159, 217, 190,  57, 179,\n",
       "        183,  14, 170, 115,  40, 119,  12,   8, 142, 130, 185],\n",
       "       [ 65, 151, 181, 148, 153, 203,  98, 187, 108, 131, 124,  24,  79,\n",
       "        180,  36, 190, 109, 148, 133,  90, 105,  56,  31,  62, 195, 157,\n",
       "        179, 205,  88,  85, 201,  81, 190,  19, 103,  16,  82, 139, 116,\n",
       "         63,  25, 180, 124, 166, 196, 179, 202, 143, 190, 174]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"to_idx\", TextFeaturizer(max_features=VOCAB_SIZE)),\n",
    "    (\"pad\", Padder2d(max_len=MAX_LEN, pad_value=VOCAB_SIZE, dtype=int)),\n",
    "]\n",
    "Pipeline(steps).fit_transform(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        rec_layer_type=\"lstm\",\n",
    "        num_units=128,\n",
    "        num_layers=2,\n",
    "        dropout=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.rec_layer_type = rec_layer_type.lower()\n",
    "        self.num_units = num_units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE + 1, embedding_dim=self.embedding_dim)\n",
    "\n",
    "        rec_layer = {\"lstm\": nn.LSTM, \"gru\": nn.GRU}[self.rec_layer_type]\n",
    "        # We have to make sure that the recurrent layer is batch_first,\n",
    "        # since sklearn assumes the batch dimension to be the first\n",
    "        self.rec = rec_layer(\n",
    "            self.embedding_dim, self.num_units, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(self.num_units, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        embeddings = self.emb(X)\n",
    "        # from the recurrent layer, only take the activities from the last sequence step\n",
    "        if self.rec_layer_type == \"gru\":\n",
    "            _, rec_out = self.rec(embeddings)\n",
    "        else:\n",
    "            _, (rec_out, _) = self.rec(embeddings)\n",
    "        rec_out = rec_out[-1]  # take output of last RNN layer\n",
    "        drop = F.dropout(rec_out, p=self.dropout)\n",
    "        # Remember that the final non-linearity should be softmax, so that our predict_proba\n",
    "        # method outputs actual probabilities!\n",
    "        out = F.softmax(self.output(drop), dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.append(\n",
    "    (\n",
    "        \"net\",\n",
    "        NeuralNetClassifier(\n",
    "            RNNClassifier,\n",
    "            device=(\"cuda\" if USE_CUDA else \"cpu\"),\n",
    "            max_epochs=5,\n",
    "            lr=0.01,\n",
    "            optimizer=torch.optim.RMSprop,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7681\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.6933\u001b[0m  1.2950\n",
      "      2        \u001b[36m0.7042\u001b[0m       \u001b[32m0.5112\u001b[0m        \u001b[35m0.6925\u001b[0m  1.3084\n",
      "      3        \u001b[36m0.7006\u001b[0m       \u001b[32m0.5162\u001b[0m        0.7090  1.3277\n",
      "      4        \u001b[36m0.6522\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.6275\u001b[0m  1.3339\n",
      "      5        \u001b[36m0.5431\u001b[0m       \u001b[32m0.7296\u001b[0m        \u001b[35m0.5505\u001b[0m  1.4967\n",
      "CPU times: user 21.1 s, sys: 1.84 s, total: 23 s\n",
      "Wall time: 23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('to_idx',\n",
       "                 TextFeaturizer(analyzer='word', binary=False,\n",
       "                                decode_error='strict',\n",
       "                                dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                input='content', lowercase=True, max_df=1.0,\n",
       "                                max_features=1000, min_df=1, ngram_range=(1, 1),\n",
       "                                preprocessor=None, stop_words=None,\n",
       "                                strip_accents=None,\n",
       "                                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                tokenizer=None, unknown_token=None,\n",
       "                                vocabulary=None)),\n",
       "                ('pad',\n",
       "                 Padder2d(dtype=<class 'int'>, max_len=50, pad_value=1000)),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=RNNClassifier(\n",
       "    (emb): Embedding(1001, 128)\n",
       "    (rec): LSTM(128, 128, num_layers=2, batch_first=True)\n",
       "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('to_idx',\n",
       "                 TextFeaturizer(analyzer='word', binary=False,\n",
       "                                decode_error='strict',\n",
       "                                dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                input='content', lowercase=True, max_df=1.0,\n",
       "                                max_features=1000, min_df=1, ngram_range=(1, 1),\n",
       "                                preprocessor=None, stop_words=None,\n",
       "                                strip_accents=None,\n",
       "                                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                tokenizer=None, unknown_token=None,\n",
       "                                vocabulary=None)),\n",
       "                ('pad',\n",
       "                 Padder2d(dtype=<class 'int'>, max_len=50, pad_value=1000)),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=RNNClassifier(\n",
       "    (emb): Embedding(1001, 128)\n",
       "    (rec): LSTM(128, 128, num_layers=2, batch_first=True)\n",
       "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(net__verbose=0, net__train_split=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"to_idx__stop_words\": [\"english\", None],\n",
    "    \"to_idx__lowercase\": [False, True],\n",
    "    \"to_idx__ngram_range\": [(1, 1), (2, 2)],\n",
    "    \"net__module__embedding_dim\": stats.randint(32, 256 + 1),\n",
    "    \"net__module__rec_layer_type\": [\"gru\", \"lstm\"],\n",
    "    \"net__module__num_units\": stats.randint(32, 256 + 1),\n",
    "    \"net__module__num_layers\": [1, 2, 3],\n",
    "    \"net__module__dropout\": stats.uniform(0, 0.9),\n",
    "    \"net__lr\": [10 ** (-stats.uniform(1, 5).rvs()) for _ in range(NUM_CV_STEPS)],\n",
    "    \"net__max_epochs\": [5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    pipe, params, n_iter=NUM_CV_STEPS, verbose=2, refit=False, scoring=\"accuracy\", cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.5s\n",
      "[CV] net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.4s\n",
      "[CV] net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0006487299427756309, net__max_epochs=10, net__module__dropout=0.47600542777761407, net__module__embedding_dim=120, net__module__num_layers=2, net__module__num_units=197, net__module__rec_layer_type=lstm, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.4s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.7s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.8s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.33141738585649316, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=111, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.8s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   7.0s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   7.1s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.4153314260276387, net__module__embedding_dim=179, net__module__num_layers=3, net__module__num_units=199, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   7.1s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   5.2s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   5.1s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=10, net__module__dropout=0.09531684646901292, net__module__embedding_dim=183, net__module__num_layers=3, net__module__num_units=235, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   5.2s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   4.9s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   4.9s\n",
      "[CV] net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00018027374480055714, net__max_epochs=5, net__module__dropout=0.2917269070138927, net__module__embedding_dim=165, net__module__num_layers=3, net__module__num_units=49, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   4.9s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   5.6s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   5.2s\n",
      "[CV] net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english \n",
      "[CV]  net__lr=1.5194492443505814e-06, net__max_epochs=10, net__module__dropout=0.6278680763345383, net__module__embedding_dim=201, net__module__num_layers=2, net__module__num_units=67, net__module__rec_layer_type=gru, to_idx__lowercase=True, to_idx__ngram_range=(2, 2), to_idx__stop_words=english, total=   5.1s\n",
      "[CV] net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.2s\n",
      "[CV] net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.3s\n",
      "[CV] net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None \n",
      "[CV]  net__lr=9.686862153084538e-05, net__max_epochs=10, net__module__dropout=0.6756175270966106, net__module__embedding_dim=131, net__module__num_layers=2, net__module__num_units=172, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=None, total=   4.2s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   2.7s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   2.7s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=5, net__module__dropout=0.09184032967322527, net__module__embedding_dim=159, net__module__num_layers=1, net__module__num_units=163, net__module__rec_layer_type=gru, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   2.7s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   6.1s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   6.1s\n",
      "[CV] net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None \n",
      "[CV]  net__lr=0.0007615983654766594, net__max_epochs=10, net__module__dropout=0.5611590910186814, net__module__embedding_dim=239, net__module__num_layers=2, net__module__num_units=149, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(2, 2), to_idx__stop_words=None, total=   6.1s\n",
      "[CV] net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   4.4s\n",
      "[CV] net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   4.4s\n",
      "[CV] net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english \n",
      "[CV]  net__lr=0.00121001960211435, net__max_epochs=10, net__module__dropout=0.3318526535948677, net__module__embedding_dim=229, net__module__num_layers=3, net__module__num_units=32, net__module__rec_layer_type=lstm, to_idx__lowercase=False, to_idx__ngram_range=(1, 1), to_idx__stop_words=english, total=   4.4s\n",
      "CPU times: user 2min 38s, sys: 7.29 s, total: 2min 46s\n",
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('to_idx',\n",
       "                                              TextFeaturizer(analyzer='word',\n",
       "                                                             binary=False,\n",
       "                                                             decode_error='strict',\n",
       "                                                             dtype=<class 'numpy.int64'>,\n",
       "                                                             encoding='utf-8',\n",
       "                                                             input='content',\n",
       "                                                             lowercase=True,\n",
       "                                                             max_df=1.0,\n",
       "                                                             max_features=1000,\n",
       "                                                             min_df=1,\n",
       "                                                             ngram_range=(1, 1),\n",
       "                                                             preprocessor=None,\n",
       "                                                             stop_words=None,\n",
       "                                                             strip_accents=None,\n",
       "                                                             token_patter...\n",
       "                                        'net__module__num_units': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe170b79dd8>,\n",
       "                                        'net__module__rec_layer_type': ['gru',\n",
       "                                                                        'lstm'],\n",
       "                                        'to_idx__lowercase': [False, True],\n",
       "                                        'to_idx__ngram_range': [(1, 1), (2, 2)],\n",
       "                                        'to_idx__stop_words': ['english',\n",
       "                                                               None]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X[:5000], y[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
